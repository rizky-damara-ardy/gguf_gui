# Use NVIDIA's CUDA base image
ARG ARG_BUILD_FROM="nvcr.io/nvidia/cuda:12.5.0-devel-ubuntu22.04"
ARG DEBIAN_FRONTEND=noninteractive
FROM $ARG_BUILD_FROM as base

# Define user configurations
ARG ARG_USERNAME="app"
ARG ARG_USER_UID=1337
ARG ARG_USER_GID=$ARG_USER_UID
ENV USERNAME $ARG_USERNAME
ENV USER_UID $ARG_USER_UID
ENV USER_GID $ARG_USER_GID
ENV HOME /app
ENV PATH=/app:/app/llama.cpp:$PATH
ENV LLAMA_CUDA=1

# Install required packages
RUN apt-get update && \
    apt-get install -y --no-install-recommends python3 python3-dev python3-pip python3-venv git \
    build-essential cmake gcc curl openssl libssl-dev liblzma-dev libffi-dev libsqlite3-dev

# Create application directory and user
RUN mkdir -p $HOME && \
    groupadd --gid $USER_GID $USERNAME && \
    adduser --uid $USER_UID --gid $USER_GID $USERNAME --no-create-home --home $HOME --disabled-password --gecos "" && \
    chown -R $USERNAME:$USERNAME /app

USER $USERNAME

# Clone necessary repositories
RUN git clone --depth=1 https://github.com/rizky-damara-ardy/gguf_gui.git /app
RUN git clone --depth=1 https://github.com/ggerganov/llama.cpp.git /app/llama.cpp

WORKDIR /app

# Install pyenv and Python
RUN curl https://pyenv.run | bash && \
    export PYENV_ROOT="$HOME/.pyenv" && \
    command -v pyenv >/dev/null || export PATH="$PYENV_ROOT/bin:$PATH" && \
    eval "$(pyenv init -)" && \
    pyenv install 3.11 && \
    pyenv global 3.11 && \
    python -m venv .venv

# Activate virtual environment and install Python dependencies
RUN . .venv/bin/activate && \
    pip install --upgrade huggingface_hub pip streamlit watchdog llama-cpp-python && \
	# Install torch (CPU or CUDA version based on your needs)
    pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu124 && \
	# Install sentencepiece
    pip install sentencepiece && \
    # Check if the requirements file exists before attempting to install
    if [ -f "llama.cpp/requirements/requirements-convert-hf-to-gguf.txt" ]; then \
        pip install -r "llama.cpp/requirements/requirements-convert-hf-to-gguf.txt"; \
    else \
        echo "Requirements file not found, skipping installation."; \
    fi

# Build llama.cpp using CMake
RUN cd llama.cpp && \
    mkdir build && \
    cd build && \
    cmake .. && \
    make -j "$(nproc)" && \
    cd ../..

# Create an entrypoint script to activate the virtual environment
RUN echo "#!/bin/bash" > /app/entrypoint.sh && \
    echo 'export PYENV_ROOT="$HOME/.pyenv"' >> /app/entrypoint.sh && \
    echo 'command -v pyenv >/dev/null || export PATH="$PYENV_ROOT/bin:$PATH"' >> /app/entrypoint.sh && \
    echo 'eval "$(pyenv init -)"' >> /app/entrypoint.sh && \
    echo ". .venv/bin/activate" >> /app/entrypoint.sh && \
    echo "cd /app" >> /app/entrypoint.sh && \
    echo "exec \"\$@\"" >> /app/entrypoint.sh && \
    chmod +x /app/entrypoint.sh

# Set up volume and expose port
VOLUME [ "/app/models" ]
EXPOSE 8501

# Set command to run the application
CMD [ "/app/entrypoint.sh", "streamlit", "run", "main.py", "--browser.serverAddress", "0.0.0.0" ]
